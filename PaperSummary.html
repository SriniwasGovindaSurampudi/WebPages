<!DOCTYPE html>
<html>
<head>
	<meta charset="UTF-8">
	<title>Summary of Papers Read</title>
	<style>
		table {
			width: 100%
	}
	tale, th, td {
		border: 1px solid black;
		border-collapse: collapse;
	}
	th {
		padding: 5px;
		text-align: center;
	}
	td {
		padding: 5px;
		text-align: justify;
	}
	table tr:nth-child(even) {
		background-color: #fff;
	}
	table tr:nth-child(odd) {
		background-color: #eee;
	}
	table th {
		background-color: black;
		color: white;
	}
	a:link {
    color: green;
    background-color: transparent;
    text-decoration: none;
	}
	a:visited {
	    color: green;
	    background-color: transparent;
	    text-decoration: none;
	}
	a:hover {
 	   color: red;
 	   background-color: transparent;
 	   text-decoration: underline;
	}
	a:active {
 	   color: yellow;
 	   background-color: transparent;
 	   text-decoration: underline;
	}
	h1 {
		text-align: center;
	}
	select {
		color: blue;
	}
	</style>
</head>
<body>
	<h1>SUMMARY OF PAPERS</h1>
	<table>
		<tr>
			<th style="width:200px">Title</th>
			<th style="width:300px">Summary</th>
			<th style="width:150px">Authors</th>
			<th style="width:50px">Publication Year</th>
			<th style="width:150px">Citation(Chicago)</th>
			<th style="width:50px">Link</th>
		</tr>
		<tr>
			<td>A Tutorial on Spectral Clustering</td>
			<td>Three tyes of graph laplacians, unnormalized, random walk and symmetric graph laplacians, and their properties are described. Their related spectral clustering algorithms are derived from scratch from several different approaches viz graph-cuts, random-walk and perturbation theory point of views.</td>
			<td>Ulrike von Luxburg</td>
			<td>2007</td>
			<td>Von Luxburg, Ulrike. "A tutorial on spectral clustering." Statistics and computing 17, no. 4 (2007): 395-416.</td>
			<td>
				<a href="http://arxiv.org/pdf/0711.0189.pdf" target="_blank">Find here</a>
			</td>
		</tr>
		<tr>
			<td>Laplacian Eigenmaps for Dimensionality Reduction and Data Representation</td>
			<td>This paper deals with the problem of appropriate representation of data lying on a low dimensional manifold, which is in a higher dimensional space. The paper shows correspondences between the proposed method and Laplace Beltrami operator on manifolds  and connects with the heat equation. The geometrically motivated algorithm is an efficient approach for nonlinear dimensionality reduction. This algorithm uses the eigen values and eigen vectors of graph Laplacian. This is very much related to spectral clustering algorithm, just that the eigen vectors are used as bases for the embedding to reduce dimensionality of data.</td>
			<td>Mikhail Belkin, Partha Niyogi</td>
			<td>2003</td>
			<td>Belkin, Mikhail, and Partha Niyogi. "Laplacian eigenmaps for dimensionality reduction and data representation." Neural computation 15, no. 6 (2003): 1373-1396.</td>
			<td>
				<a href="https://www.cs.rochester.edu/u/stefanko/Teaching/09CS446/Laplacian.pdf" target="_blank">Find here</a>
			</td>

		</tr>
		<tr>
			<td>Network diffusion accurately models the relationship between structural and functional brain connectivity networks</td>
			<td>This paper hypothesises that diffusion of signals on structural connection of the brain network can predict functinoal connectivity. Considering only one ROI actice at a time, the activation signals reaching its neighbor ROIs, through diffusion, at any given time is hypothesised as the pairwise correlation between these ROIs. These individually and independently active ROI activation diffusions are stacked together and hypothesised that the overall functional correlaton matrix can match at a particular scale.</td>
			<td>Farras Abdelnour, Henning U. Voss, Ashish Raj</td>
			<td>2013</td>
			<td>Abdelnour, Farras, Henning U. Voss, and Ashish Raj. "Network diffusion accurately models the relationship between structural and functional brain connectivity networks." Neuroimage 90 (2014): 335-347.</td>
			<td>
				<a href="http://www.sciencedirect.com/science/article/pii/S1053811913012597" target="_blank">Find here</a>
			</td>
		</tr>
		<tr>
			<td>Machine learning with brain graphs: predictive modeling approaches for functional imaging in systems neuroscience</td>
			<td>This paper clearly explains the different stages of machine learning with brain graphs. How the time series data are processed from the voxels, how these time series are used to form brain graphs, and then how are statistical machine learning methods applied for predictive modelling. </td>
			<td>Jonas Richiardi, Sophie Achard, Horst Bunke, and Dimitri Van De Ville</td>
			<td>2013</td>
			<td>Richiardi, Jonas, Sophie Achard, Horst Bunke, and Dimitri Van De Ville. "Machine learning with brain graphs: predictive modeling approaches for functional imaging in systems neuroscience." Signal Processing Magazine, IEEE 30, no. 3 (2013): 58-70.</td>
			<td>
				<a href="http://web.stanford.edu/~richiard/papers/2013-Richiardi-IEEESigProcMag.pdf" target="_blank">Find here</a>
			</td>
		</tr>
		<tr>
			<td>Modularity and community structure in networks</td>
			<td>This paper defines a new graph matrix called modularity matrix. Spectrum of this matrix is used to detect the community structure in a much efficient way</td>
			<td>M. E. J. Newman</td>
			<td>2006</td>
			<td>Newman, Mark EJ. "Modularity and community structure in networks." Proceedings of the national academy of sciences 103, no. 23 (2006): 8577-8582.</td>
			<td>
				<a href="http://www.pnas.org/content/103/23/8577.full" target="_blank">Find here</a>
			</td>
		</tr>
		<tr>
			<td>The UCLA multimodal connectivity database: a web-based platform for brain connectivity matrix sharing and analysis</td>
			<td>This paper mentions about the <a href="http://umcd.humanconnectomeproject.org" target="_blank">website</a> for accessing and analysing various structural and functional matrices, which are publically available. To demonstrate the site’s functionality, whole brain functional and structural connectivity matrices are derived from 60 subjects’ (ages 26–45) resting state fMRI (rs-fMRI) and dwMRI data and uploaded to the site. Graph theoretical properties can be applied on the connectivity matrices to infer about global and local properties. Functional connectivity matrices are derived from resting state fMRI, dwMRI, and structural connectivity matrices are derived from DTI, MRI methods.</td>
			<td>Jesse A. Brown, Jeffrey D. Rudie, Anita Bandrowski, John D. Van Horn and Susan Y. Bookheimer</td>
			<td>2012</td>
			<td>Brown, Jesse A., Jeffrey D. Rudie, Anita Bandrowski, John D. Van Horn, and Susan Y. Bookheimer. "The UCLA multimodal connectivity database: a web-based platform for brain connectivity matrix sharing and analysis." Frontiers in neuroinformatics 6 (2012): 28.</td>
			<td>
				<a href="https://scholar.google.co.in/scholar?lookup=0&q=The+UCLA+multimodal+connectivity+database:+a+web-based+platform+for+brain+connectivity+matrix+sharing+and+analysis&hl=en&as_sdt=0,5" target="_blank">Find here</a>
			</td>
		</tr>
		<tr>
			<td>Co-clustering documents and words using Bipartite Spectral Graph Partitioning</td>
			<td>This paper introduces the idea of clustering two different datasets, which are related to each other and independently clustered well, together. The idea is to form a matrix of size #words by #documents, and then use the adjacency matrix of the induced graph whose entries indicate presence of a word in a document. SVD of a derived matrix using the laplacian of the graph provides clusters of both words and documents simultaneously. This technique is extended for multiple partions also.</td>
			<td>Inderjit S. Dhillon </td>
			<td>2001</td>
			<td>Dhillon, Inderjit S. "Co-clustering documents and words using bipartite spectral graph partitioning." In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 269-274. ACM, 2001.</td>
			<td>
				<a href="http://www.cs.utexas.edu/users/inderjit/public_papers/kdd_bipartite.pdf" target="_blank">Find here</a>
			</td>
		</tr>
		<tr>
			<td>Clustering with Multiple Graphs</td>
			<td>This paper proposes a novel method to combine information provided by different graphs on the same set of vertices for better clustering of those vretices. The method called 'Linked Matrix Factorization (LMF)' formulates the problem of extracting the common information from all the graphs as an optimization problem and solves it with quasi-Newton method Limited memory BFGS. The paper also presents a semi-supervised algorithm for the same purpose of clustering.</td>
			<td>Tang, Wei, Zhengdong Lu, and Inderjit S. Dhillon</td>
			<td>2009</td>
			<td>Tang, Wei, Zhengdong Lu, and Inderjit S. Dhillon. "Clustering with multiple graphs." In Data Mining, 2009. ICDM'09. Ninth IEEE International Conference on, pp. 1016-1021. IEEE, 2009.</td>
			<td>
				<a href="http://research.microsoft.com/pubs/147190/icdm09final.pdf" target="_blank">Find here</a>
			</td>
		</tr>
		<tr>
			<td>Clustering With Multi-Layer Graphs: A Spectral Perspective</td>
			<td>This paper focusses on clustering nodes in a graph using multiple view-points or multi-layers of the graph. It proposes two methods, both based on deriving 'joint-spectrum' of the whole graph of multiple layers; i.e a set of eigenvectors that capture the essence of the multiple layers. First method computes eigenvectors of the graph that tend to reflect average granularity provided by each layer weighted equally. The second method weighs the layer providing the most information more, computes its eigenvectors and uses these to regularize the eigenvectors of the subsequent layers iteratively to obtain the final set of eigenvectors that represents overall properties from all the layers. Second method is performs better than the first.</td>
			<td>Xiaowen Dong, Pascal Frossard, Pierre Vandergheynst, and Nikolai Nefedov</td>
			<td>2012</td>
			<td>Dong, Xiaowen, Pascal Frossard, Pierre Vandergheynst, and Nikolai Nefedov. "Clustering with multi-layer graphs: A spectral perspective." Signal Processing, IEEE Transactions on 60, no. 11 (2012): 5820-5831.</td>
			<td>
				<a href="http://web.media.mit.edu/~xdong/paper/tsp2012.pdf" target="_blank">Find here</a>
			</td>
		</tr>
		<tr>
			<td>Gaussian mixture models</td>
			<td>This paper summarizes gaussian mixture models, how EM is applied for parameter estimation. This paper concisely presents the concepts involved in GMM.</td>
			<td>Douglas Reynolds</td>
			<td>2015</td>
			<td>Reynolds, Douglas. "Gaussian mixture models." Encyclopedia of Biometrics (2015): 827-832.</td>
			<td>
				<a href="http://llwebprod2.ll.mit.edu/mission/cybersec/publications/publication-files/full_papers/0802_Reynolds_Biometrics-GMM.pdf" target="_blank">Find here</a>
			</td>
		</tr>
	</table>
</body>
</html>